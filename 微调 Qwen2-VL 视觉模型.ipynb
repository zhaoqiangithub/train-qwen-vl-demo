{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ä½¿ç”¨ModelScopeé•œåƒ\n",
    "os.environ['UNSLOTH_USE_MODELSCOPE'] = '1'\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "from unsloth import FastVisionModel  # ç”¨äºè§†è§‰æ¨¡å‹ï¼Œå¦‚æœæ˜¯è¯­è¨€æ¨¡å‹åˆ™ä½¿ç”¨ FastLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ”¯æŒçš„4bité‡åŒ–æ¨¡å‹åˆ—è¡¨ï¼Œå¯ä»¥å®ç°4å€æ›´å¿«çš„ä¸‹è½½é€Ÿåº¦ä¸”ä¸å¥½å‘ç”Ÿå†…å­˜æº¢å‡ºOOM\n",
    "fourbit_models = [\n",
    "    # Llama 3.2 ç³»åˆ—è§†è§‰æ¨¡å‹\n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\", # Llama 3.2 æ”¯æŒè§†è§‰ä»»åŠ¡çš„æŒ‡ä»¤ç‰ˆæœ¬\n",
    "    \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\", # å¯ä»¥åœ¨80GBæ˜¾å¡ä¸Šè¿è¡Œ\n",
    "    \"unsloth/Llama-3.2-90B-Vision-bnb-4bit\",\n",
    "\n",
    "    # Pixtral ç³»åˆ—è§†è§‰æ¨¡å‹\n",
    "    \"unsloth/Pixtral-12B-2409-bnb-4bit\",              # Pixtral å¯ä»¥åœ¨ 16GB æ˜¾å­˜ä¸Šè¿è¡Œ\n",
    "    \"unsloth/Pixtral-12B-Base-2409-bnb-4bit\",         # Pixtral base model\n",
    "\n",
    "    # Qwen2 ç³»åˆ—è§†è§‰æ¨¡å‹\n",
    "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",          # Qwen2 VL è§†è§‰æ¨¡å‹\n",
    "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Qwen2-VL-72B-Instruct-bnb-4bit\",\n",
    "\n",
    "    # Llava ç³»åˆ—è§†è§‰æ¨¡å‹\n",
    "    \"unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit\",      # æ”¯æŒæ‰€æœ‰ Llava å˜ä½“!\n",
    "    \"unsloth/llava-1.5-7b-hf-bnb-4bit\",\n",
    "] # æ›´å¤šæ¨¡å‹å¯ä»¥åœ¨ https://huggingface.co/unsloth ä¸Šé¢æ‰¾åˆ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.2: Fast Qwen3_Vl patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 7.996 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b4ff3873ea470b9cecb14f049b2522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    # model_name=\"/home/zq/projects/models/unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\", # é€‰æ‹©åŠ è½½æœ¬åœ°æ¨¡å‹\n",
    "    model_name=\"/home/zq/projects/models/Qwen/Qwen3-VL-4B-Instruct\", # é€‰æ‹©åŠ è½½æœ¬åœ°æ¨¡å‹\n",
    "    load_in_4bit = True, # ä½¿ç”¨ 4bit é‡åŒ–å‡å°‘å†…å­˜ä½¿ç”¨ã€‚ False åˆ™ä½¿ç”¨ 16bit LoRA è®­ç»ƒ\n",
    "    use_gradient_checkpointing = \"unsloth\", # è®¾ç½®ä¸ºTrue æˆ–è€… \"unsloth\" ä»¥æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼Œæ¢¯åº¦æ£€æŸ¥ç‚¹æŠ€æœ¯èŠ‚çœæ˜¾å­˜ã€‚UnslothåŸºäº transformers triton å®ç°çš„ï¼Œéƒ½æ˜¯HuggingFaceå‡ºå“çš„\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ·»åŠ äº† LoRA é€‚é…å™¨ï¼Œç”¨äºå‚æ•°é«˜æ•ˆå¾®è°ƒ - è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿé«˜æ•ˆåœ°è®­ç»ƒæ‰€æœ‰å‚æ•°çš„ 1%ã€‚\n",
    "\n",
    "[æ–°åŠŸèƒ½] è¿˜æ”¯æŒä»…å¾®è°ƒæ¨¡å‹çš„è§†è§‰éƒ¨åˆ†æˆ–è¯­è¨€éƒ¨åˆ†ã€‚æˆ–è€…æ‚¨å¯ä»¥é€‰æ‹©ä¸¤è€…ï¼æ‚¨è¿˜å¯ä»¥é€‰æ‹©å¾®è°ƒæ³¨æ„åŠ›æˆ– MLP å±‚ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # æ˜¯å¦å¾®è°ƒè§†è§‰ç›¸å…³å±‚\n",
    "    finetune_language_layers   = False, # æ˜¯å¦å¾®è°ƒè¯­è¨€ç›¸å…³å±‚ï¼Œè¯­è¨€æ¨¡å‹ä¸å¾®è°ƒ\n",
    "    finetune_attention_modules = True, # æ˜¯å¦å¾®è°ƒæ³¨æ„åŠ›ç›¸å…³å±‚\n",
    "    finetune_mlp_modules       = True, # æ˜¯å¦å¾®è°ƒMLPå±‚ï¼Œå½±å“éªŒè¯é›†å‡†ç¡®ç‡\n",
    "\n",
    "    # Lora æ ¸å¿ƒå‚æ•°\n",
    "    r = 16,           # è¶Šå¤§è¶Šå‡†ï¼Œä½†å®¹æ˜“è¿‡æ‹Ÿåˆ\n",
    "    lora_alpha = 16,  # æ¨èè‡³å°‘ alpha == r ï¼Œå½±å“è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ”¶æ•›é€Ÿåº¦å’Œæ•ˆæœ\n",
    "    lora_dropout = 0, # dropout ratio ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆçš„æ‰‹æ®µ\n",
    "    bias = \"none\",    # æ˜¯å¦æ·»åŠ åç½®é¡¹\n",
    "    \n",
    "    # å…¶å®ƒé…ç½®å‚æ•°\n",
    "    random_state = 3407, # éšæœºç§å­ï¼Œç¡®ä¿ä½¿ç”¨å¯é‡å¤æ€§\n",
    "    use_rslora = False,  # æ˜¯å¦ä½¿ç”¨ rank stabilized LoRA\n",
    "    loftq_config = None, # LoftQ é…ç½®ï¼Œç”¨äºé‡åŒ–\n",
    "    # target_modules = \"all-linear\", # å¯é€‰é¡¹! å¯ä»¥çŸ¥é“éœ€è¦åº”ç”¨LoRAçš„å…·ä½“æ¨¡å—\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### æˆ‘ä»¬å°†ä½¿ç”¨æ‰‹å†™æ•°å­¦å…¬å¼çš„æ ·æœ¬æ•°æ®é›†ã€‚ç›®æ ‡æ˜¯å°†è¿™äº›å›¾åƒè½¬æ¢ä¸ºè®¡ç®—æœºå¯è¯»çš„å½¢å¼ - å³ LaTeX å½¢å¼ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ¸²æŸ“å®ƒã€‚è¿™å¯¹äºå¤æ‚çš„å…¬å¼éå¸¸æœ‰ç”¨ã€‚https://huggingface.co/datasets/unsloth/LaTeX_OCR https://huggingface.co/datasets/linxy/LaTeX_OCR\n",
    "\n",
    "å·¦è¾¹çš„æ¸²æŸ“å‡ºæ¥çš„å…¬å¼ï¼ˆé—®é¢˜ï¼‰ï¼Œå³è¾¹æ˜¯LaTexçš„æ–‡æœ¬ï¼ˆç­”æ¡ˆï¼‰ï¼Œdatasetsæ˜¯hugging faceçš„ä¸€ä¸ªæ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5c5e97e50b4057901305ad85ef6872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3948eb9fb7894c0da872aef6fceeeaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"./data/unsloth/LaTeX_OCR\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 68686\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=320x50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H ^ { \\\\prime } = \\\\beta N \\\\int d \\\\lambda \\\\biggl \\\\{ \\\\frac { 1 } { 2 \\\\beta ^ { 2 } N ^ { 2 } } \\\\partial _ { \\\\lambda } \\\\zeta ^ { \\\\dagger } \\\\partial _ { \\\\lambda } \\\\zeta + V ( \\\\lambda ) \\\\zeta ^ { \\\\dagger } \\\\zeta \\\\biggr \\\\} \\\\ .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle H ^ { \\prime } = \\beta N \\int d \\lambda \\biggl \\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\biggr \\} \\ .$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å¯ä»¥ç›´æ¥é€šè¿‡æµè§ˆå™¨æ¸²æŸ“\n",
    "from IPython.display import display, Math, Latex\n",
    "latex = dataset[2][\"text\"]\n",
    "display(Math(latex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ•´ç†æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰€æœ‰çš„è§†è§‰å¾®è°ƒä»»åŠ¡ï¼Œæ ¼å¼åŒ–å½¢å¼å¦‚ä¸‹ï¼Œ\n",
    "[\n",
    "{ \"role\": \"user\",\n",
    "  \"content\": [{\"type\": \"text\",  \"text\": Q}, {\"type\": \"image\", \"image\": image} ]\n",
    "},\n",
    "{ \"role\": \"assistant\",\n",
    "  \"content\": [{\"type\": \"text\",  \"text\": A} ]\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é—®é¢˜Qæœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯ Imageå›¾ç‰‡ï¼Œä¸€ä¸ªæ˜¯æŒ‡ä»¤ instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Write the LaTeX representation for this image.\" # æŒ‡ä»¤éƒ¨åˆ†ï¼Œé—®é¢˜çš„ä¸€éƒ¨åˆ†\n",
    "\n",
    "def convert_to_conversation(sample): # simpleæ˜¯æ•°æ®é›†ä¸­çš„ä¸€æ¡æ ·æœ¬ï¼Œ å°†æ•°æ®é›†æ ·æœ¬è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼\n",
    "    conversation = [\n",
    "        { \"role\": \"user\",\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
    "            {\"type\" : \"image\", \"image\" : sample[\"image\"]} ]\n",
    "        },\n",
    "        { \"role\" : \"assistant\",  # åŠ©æ‰‹ï¼Œå›ç­”éƒ¨åˆ†ã€‚Vision language Models è§†è§‰è¯­è¨€æ¨¡å‹\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : sample[\"text\"]} ]\n",
    "        },\n",
    "    ]\n",
    "    return { \"messages\" : conversation }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢æ˜¯å‡½æ•°æ³¨å†Œå®šä¹‰ï¼Œä¸‹é¢æ˜¯å‡½æ•°æ‰§è¡Œï¼Œåšæ•°æ®çš„è½¬æ¢ï¼ŒforæŠŠæ¯ä¸ªæ ·æœ¬æ‹¿å‡ºæ¥ï¼Œäº¤ç»™ä¸Šé¢å°è£…å¥½çš„å‡½æ•°åšè½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Write the LaTeX representation for this image.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'}]}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_dataset[0]  #  å›¾ç‰‡éƒ¨åˆ†æ‰“å°çš„æ˜¯  'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>}]}, å¯¹åº”å¯¹åº”çš„ç±»å‹æ˜¯PILï¼Œåœ¨pythonä¸­æ˜¯Pillowåº“ä¸­çš„Imageç±»å‹; RGBæ˜¯å½©è‰²å›¾åƒçº¢ç»¿è“ä¸‰é€šé“; å¤§å°160x40åƒç´ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è¿›è¡Œä»»ä½•å¾®è°ƒä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹ç¬¬ä¸€ä¸ªä¾‹å­çš„æ¨¡å‹è¾“å‡ºæ˜¯ä»€ä¹ˆï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$H ^ { \\prime } = \\beta N \\int d \\lambda \\left\\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\right\\} .$$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model) # æ¨ç†æ¨¡å¼! è®­ç»ƒä¹‹å‰æŠŠæ¨¡å‹åˆ‡æ¢æˆæ¨ç†æ¨¡å¼ï¼ŒæŠŠæ•°æ®ä¼ ç»™ä»–\n",
    "\n",
    "image = dataset[2][\"image\"]                               # æ‰¾ä¸€æ¡æ•°æ®\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "messages = [                                             # æ„å»ºæ¶ˆæ¯ä½“\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True) # tokenizerè½¬åŒ–æˆå¤§æ¨¡å‹å¯è¯†åˆ«çš„è¾“å…¥æ ¼å¼\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)   # åˆ›å»ºä¸€ä¸ªTextStreamerï¼Œé€šè¿‡å®ƒå¯ä»¥å®æ—¶è¾“å‡ºç”Ÿæˆçš„æ–‡æœ¬ã€‚  é€šè¿‡model.generateæŠŠè¾“å…¥ç»™æ¨¡å‹ï¼Œç»™å‡ºç›¸åº”çš„é¢„æµ‹ã€‚\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,   # è¾“å‡ºçš„å’ŒçœŸå®çš„é¢„æµ‹æš‚æ—¶è¿˜æœ‰å·®è·\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H ^ { \\\\prime } = \\\\beta N \\\\int d \\\\lambda \\\\biggl \\\\{ \\\\frac { 1 } { 2 \\\\beta ^ { 2 } N ^ { 2 } } \\\\partial _ { \\\\lambda } \\\\zeta ^ { \\\\dagger } \\\\partial _ { \\\\lambda } \\\\zeta + V ( \\\\lambda ) \\\\zeta ^ { \\\\dagger } \\\\zeta \\\\biggr \\\\} \\\\ .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®­ç»ƒæ¨¡å‹ï¼ˆé¢„æµ‹çš„æ•°æ®ï¼Œå’ŒçœŸå®çš„æ•°æ®æœ‰å·®è·ï¼Œå¦‚ä½•èƒ½è®©å·®è·æ›´å°ï¼Œé€šè¿‡è®­ç»ƒå¯ä»¥æ›´å°ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦ç»„ä»¶\n",
    "from unsloth import is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator  # å…³äºè§†è§‰çš„UnslothVisionDataCollatorï¼Œ è¿˜æœ‰trainer\n",
    "from trl import SFTTrainer, SFTConfig # å¾®è°ƒè®­ç»ƒå™¨å’Œé…ç½®ï¼Œæœ‰ç›‘ç£çš„è®­ç»ƒå™¨å’Œé…ç½®\n",
    "\n",
    "FastVisionModel.for_training(model) # åˆ‡æ¢è®­ç»ƒæ¨¡å¼!  æ¨ç†æ¨¡å¼å’Œè®­ç»ƒæ¨¡å¼ï¼Œæœ‰ä»€ä¹ˆåŒºåˆ«ä¹ˆã€‚\n",
    "\n",
    "# æ¨ç†æ¨¡å¼ï¼ˆé¢„æµ‹å‡ºç­”æ¡ˆï¼‰ï¼šæŠŠè¾“å…¥è¿›æ¥çš„xï¼Œç»è¿‡æ¨¡å‹ï¼Œå¾—åˆ°è¾“å‡ºyï¼›ç»™è¾“å…¥ï¼Œå¾—åˆ°è¾“å‡ºå®Œäº‹ã€‚\n",
    "# è®­ç»ƒæ¨¡å¼ï¼ˆè°ƒå‚ï¼Œä»–æœ‰çœŸå®çš„ç­”æ¡ˆè®¡ç®—lossï¼Œåå‘ä¼ æ’­æ±‚å‡ºæ¢¯åº¦ï¼Œæ ¹æ®æ¢¯åº¦è°ƒæ•´å‚æ•°ï¼‰ï¼š\n",
    "    # æŠŠè¾“å…¥è¿›æ¥çš„xï¼Œç»è¿‡æ¨¡å‹ï¼Œå¾—åˆ°è¾“å‡ºyï¼Œé™¤äº†è¾“å‡ºï¼Œè¿˜æœ‰çœŸå®çš„æ ‡ç­¾ã€‚ç„¶åè®¡ç®—yå’ŒçœŸå®æ ‡ç­¾ä¹‹é—´çš„lossï¼Œå†å°†æŸå¤±åå‘ä¼ æ’­ç»™modelå’Œå’Œmodelå‚æ•°æ›´æ–°ã€‚è°ƒæ•´ä¸­lossä¸æ–­ä¸‹é™ï¼ŒæŸå¤±å‡å°ï¼Œé¢„æµ‹çš„å’ŒçœŸå®çš„è¶Šæ¥è¶Šå°\n",
    "# è®­ç»ƒçš„ç›®çš„ï¼Œæ˜¯ä¸ºäº†æ¨ç†çš„æ—¶å€™ï¼Œé¢„æµ‹çš„ç»“æœæ›´å‡†ç¡®\n",
    "# å»ä¸éœ€è¦å…·ä½“å®ç°\n",
    "\n",
    "# é…ç½®è®­ç»ƒå™¨\n",
    "trainer = SFTTrainer(  # æ„å»ºè®­ç»ƒå™¨ï¼Œå¯¹å“ªä¸ªæ¨¡å‹è®­ç»ƒï¼Œåˆ†è¯å™¨ï¼ŒDataCollatorè¯»å–æ•°æ®å¯¹è±¡ï¼Œconverted_datasetå…·ä½“æ•°ï¼ˆè½¬æ¢å¥½çš„æ¶ˆæ¯ä½“ï¼ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼‰ï¼Œè®­ç»ƒå‚æ•°\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer), # å¿…é¡»ä½¿ç”¨!\n",
    "    train_dataset = converted_dataset,\n",
    "    args = SFTConfig(\n",
    "        # åŸºç¡€è®­ç»ƒå‚æ•°\n",
    "        per_device_train_batch_size = 2, # æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°\n",
    "        gradient_accumulation_steps = 4, # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "        warmup_steps = 5,                # é¢„çƒ­æ­¥æ•°ï¼ˆçƒ­èº«ï¼‰\n",
    "        max_steps = 30,                  # æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼ˆè®­ç»ƒå¤šå°‘æ¬¡è¿­ä»£ï¼‰\n",
    "        # num_train_epochs = 1,          # å®Œæ•´è®­ç»ƒæ—¶è®¾ç½®æ­¤é¡¹ï¼Œè€Œä¸æ˜¯ max_steps\n",
    "\n",
    "        # ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è®¾ç½®\n",
    "        learning_rate = 2e-4,            # å­¦ä¹ ç‡ï¼ˆå­¦ä¹ ç‡ç­–ç•¥ï¼‰\n",
    "        fp16 = not is_bf16_supported(),  #ï¼ˆå‚æ•°ç±»å‹ï¼‰\n",
    "        bf16 = is_bf16_supported(),\n",
    "        optim = \"adamw_8bit\",            # ä½¿ç”¨ 8bit AdamW ä¼˜åŒ–å™¨ï¼ˆé‡‡ç”¨å“ªä¸€ä¸ªä¼˜åŒ–å™¨optimizerï¼‰\n",
    "        weight_decay = 0.01,             # æƒé‡è¡°å‡ï¼ˆå­¦ä¹ ç‡ç›¸å…³çš„è¡°å‡ï¼‰\n",
    "        lr_scheduler_type = \"linear\",    # çº¿æ€§å­¦ä¹ ç‡è°ƒæ•´å™¨\n",
    "\n",
    "        seed = 3407,                     # éšæœºç§å­\n",
    "\n",
    "        # æ—¥å¿—å’Œè¾“å‡ºè®¾ç½®\n",
    "        logging_steps = 1,      # æ¯æ­¥éƒ½è®°å½•æ—¥å¿—\n",
    "        output_dir = \"outputs\", # è¾“å‡ºç›®å½•\n",
    "        report_to = \"none\",     # ä¸ä½¿ç”¨ Weights and Biases è®°å½•\n",
    "\n",
    "        # è§†è§‰å¾®è°ƒå¿…é¡»è®¾ç½®çš„ä»¥ä¸‹å‚æ•°:\n",
    "        remove_unused_columns = False,  # ä¸ç§»é™¤æœªä½¿ç”¨çš„åˆ—\n",
    "        dataset_text_field = \"\",        # æ•°æ®é›†æ–‡æœ¬å­—æ®µ\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},  # æ•°æ®é›†å‡†å¤‡å‚æ•°\n",
    "        dataset_num_proc = 4,           # æ•°æ®å¤„ç†çš„è¿›ç¨‹æ•°é‡\n",
    "        max_seq_length = 2048,          # æœ€å¤§åºåˆ—é•¿åº¦\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4060 Ti. Max memory = 7.996 GB.\n",
      "2.967 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# æ˜¾ç¤ºå½“å‰å†…å­˜ä¿¡æ¯\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 68,686 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 6,291,456 of 4,444,107,264 (0.14% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:04, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.512300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.534800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.436600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.369200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.211100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.434900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.184400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()  # æ ¸å¿ƒï¼Œè°ƒç”¨è¿›è¡Œè®­ç»ƒã€‚  \n",
    "                                # Loraçš„PEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰ï¼š0.14% trainedï¼Œä»£è¡¨è®­ç»ƒäº†0.14%çš„æ•°æ®é›†ï¼ŒLoraç®—æ³•ï¼Œåªä¼šè®­ç»ƒLora Adapterséƒ¨åˆ†çš„å‚æ•°ã€‚åŸå§‹æ¨¡å‹æ˜¯4,444,107,264 40 äº¿å‚æ•°ã€‚åªä¼šè®­ç»ƒ6,291,456 600 å¤šä¸‡å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.2888 seconds used for training.\n",
      "1.45 minutes used for training.\n",
      "Peak reserved memory = 3.271 GB.\n",
      "Peak reserved memory for training = 0.304 GB.\n",
      "Peak reserved memory % of max memory = 40.908 %.\n",
      "Peak reserved memory for training % of max memory = 3.802 %.\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå•ä½GB\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3) # æ€»ä½¿ç”¨å†…å­˜\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3) # LoRA è®­ç»ƒä½¿ç”¨çš„é¢å¤–å†…å­˜\n",
    "\n",
    "# è®¡ç®—å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)  # æ€»å†…å­˜ä½¿ç”¨æ¯”ä¾‹\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)  # LoRA è®­ç»ƒå†…å­˜æ¯”ä¾‹\n",
    "\n",
    "# æ‰“å°è®­ç»ƒæ—¶é—´ç»Ÿè®¡\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\") # è®­ç»ƒç”¨æ—¶ ç§’\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\") # è®­ç»ƒç”¨æ—¶ åˆ†é’Ÿ\n",
    "\n",
    "# æ‰“å°å†…å­˜ä½¿ç”¨ç»Ÿè®¡\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")  # å³°å€¼å ç”¨å†…å­˜\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\") # è®­ç»ƒè¿‡ç¨‹é¢å¤–ä½¿ç”¨çš„å†…å­˜\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")  # æ€»å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")  # è®­ç»ƒé¢å¤–å†…å­˜ç™¾åˆ†æ¯”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬è¿è¡Œæ¨¡å‹ï¼æ‚¨å¯ä»¥æ›´æ”¹æŒ‡ä»¤å’Œè¾“å…¥ï¼Œå°†è¾“å‡ºç•™ç©ºï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$H ^ { \\prime } = \\beta N \\int d \\lambda \\left\\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\right\\} .$$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model) # åˆ‡æ¢æ¨ç†æ¨¡å¼!\n",
    "\n",
    "image = dataset[2][\"image\"]  # ä»æ•°æ®é›†ä¸­è·å–å›¾ç‰‡\n",
    "instruction = \"Write the LaTeX representation for this image.\"  # è®¾ç½®æŒ‡ä»¤\n",
    "\n",
    "# æ„å»ºå¯¹è¯æ¶ˆæ¯æ ¼å¼\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},  # å›¾åƒè¾“å…¥\n",
    "        {\"type\": \"text\", \"text\": instruction}  # æ–‡æœ¬æŒ‡ä»¤è¾“å…¥\n",
    "    ]}\n",
    "]\n",
    "\n",
    "# ä½¿ç”¨åˆ†è¯å™¨å¤„ç†è¾“å…¥\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True) # åº”ç”¨chatæ¨¡æ¿\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,  # ä¸æ·»åŠ ç‰¹æ®Š token\n",
    "    return_tensors = \"pt\",       # è¿”å› pytorch å¼ é‡\n",
    ").to(\"cuda\")                     # ç§»åˆ° GPU ä¸Š\n",
    "\n",
    "# è®¾ç½®æ–‡æœ¬ç”Ÿæˆçš„æµå¼è¾“å‡º\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)  # åˆ›å»ºæ–‡æœ¬æµå¼è¾“å‡ºå™¨ï¼Œè·³è¿‡æç¤ºéƒ¨åˆ†\n",
    "\n",
    "# ç”Ÿæˆå“åº”å¹¶æ•è·è¾“å‡º\n",
    "output = model.generate(\n",
    "    **inputs,                  # è¾“å…¥æ•°æ®\n",
    "    streamer = text_streamer,  # ä½¿ç”¨æµå¼è¾“å‡º\n",
    "    max_new_tokens = 128,      # æœ€å¤§ç”Ÿæˆ128ä¸ªæ–°token\n",
    "    use_cache = True,          # ä½¿ç”¨ç¼“å­˜åŠ é€Ÿç”Ÿæˆ\n",
    "    temperature = 1.5,         # æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§\n",
    "    min_p = 0.1                # æœ€å°æ¦‚ç‡é˜ˆå€¼\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H ^ { \\\\prime } = \\\\beta N \\\\int d \\\\lambda \\\\biggl \\\\{ \\\\frac { 1 } { 2 \\\\beta ^ { 2 } N ^ { 2 } } \\\\partial _ { \\\\lambda } \\\\zeta ^ { \\\\dagger } \\\\partial _ { \\\\lambda } \\\\zeta + V ( \\\\lambda ) \\\\zeta ^ { \\\\dagger } \\\\zeta \\\\biggr \\\\} \\\\ .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿å­˜å’ŒåŠ è½½ã€‚ä¿å­˜Loraæ¨¡å‹ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\") # æœ¬åœ°ä¿å­˜\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿å­˜Loraæ¨¡å‹ä¹‹åï¼ŒåŠ è½½å¹¶ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.2: Fast Qwen3_Vl patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 7.996 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf84f90ceb74f26accf1146bf0c40ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\\frac { N } { M } \\in \\mathbb { Z } , \\frac { M } { P } \\in \\mathbb { Z } , \\frac { P } { Q } \\in \\mathbb { Z }$$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from unsloth import FastVisionModel\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = True, # Set to False for 16bit LoRA\n",
    "    )\n",
    "    FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "image = dataset[0][\"image\"]\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)  # temperature æ§åˆ¶éšæœºæ€§ï¼Œæ¨¡å‹ç”Ÿæˆç­”æ¡ˆçš„æ—¶å€™é—®é¢˜æœ‰å¤šé«˜ï¼Œæ¸©åº¦è¶Šé«˜ï¼Œç­”æ¡ˆéšæœºæ€§è¶Šå¤§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬è¿˜æ”¯æŒç›´æ¥ä¿å­˜ä¸º float16ã€‚å¯¹äº float16ï¼Œè¯·é€‰æ‹© merged_16bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally to 16bit\n",
    "if False: model.save_pretrained_merged(\"unsloth_finetune\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå¹¶æ¨¡å‹ï¼ŒæŠŠåŸç”Ÿçš„æ¨¡å‹ å’Œè®­ç»ƒå¥½çš„loraå‚æ•°åˆå¹¶ï¼Œä¿å­˜ä¸ºä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹\n",
    "if True: model.save_pretrained_merged(\"unsloth_finetune\", tokenizer, save_method=\"merged_4bit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
